{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Unit 4 Sprint Challenge 1 — Tree Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chicago Food Inspections\n",
    "\n",
    "For this Sprint Challenge, you'll use a dataset with information from inspections of restaurants and other food establishments in Chicago from January 1, 2010 to the present. \n",
    "\n",
    "[See this PDF](https://data.cityofchicago.org/api/assets/BAD5301B-681A-4202-9D25-51B2CAE672FF) for descriptions of the data elements included in this dataset.\n",
    "\n",
    "According to [Chicago Department of Public Health — Food Protection Services](https://www.chicago.gov/city/en/depts/cdph/provdrs/healthy_restaurants/svcs/food-protection-services.html), \"Chicago is home to 16,000 food establishments like restaurants, grocery stores, bakeries, wholesalers, lunchrooms, mobile food vendors and more. Our business is food safety and sanitation with one goal, to prevent the spread of food-borne disease. We do this by inspecting food businesses, responding to complaints and food recalls.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your challenge: Predict whether inspections failed\n",
    "\n",
    "The target is the `Fail` column.\n",
    "\n",
    "- When the food establishment failed the inspection, the target is `1`.\n",
    "- When the establishment passed, the target is `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_url = 'https://drive.google.com/uc?export=download&id=13_tP9JpLcZHSPVpWcua4t2rY44K_s4H5'\n",
    "test_url  = 'https://drive.google.com/uc?export=download&id=1GkDHjsiGrzOXoF_xcYjdzBTSjOIi3g5a'\n",
    "\n",
    "train = pd.read_csv(train_url)\n",
    "test  = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of train and test datasets\n",
    "\n",
    "assert train.shape == (51916, 17)\n",
    "assert test.shape  == (17306, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51916, 17), (17306, 17))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train and test so don't have to download multiple times\n",
    "# Plus, rename to X and y\n",
    "\n",
    "X_train = train.copy()\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target for both train1 and test1\n",
    "\n",
    "y_train = X_train['Fail']\n",
    "y_test = X_test['Fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51916, 17), (17306, 17), (51916,), (17306,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shapes\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Preprocessing\n",
    "\n",
    "You may choose which features you want to use, and whether/how you will preprocess them. You may use any tools and techniques for categorical encoding. (Pandas, category_encoders, sklearn.preprocessing, or any other library.)\n",
    "\n",
    "_To earn a score of 3 for this part, engineer new features, and use any alternative categorical encoding instead of One-Hot or Ordinal/Label encoding._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41665, 17), (13822, 17), (51916,), (17306,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Aim for 'first, fast' baseline\n",
    "# Start preprocessing by dropping nulls from all df's\n",
    "X_train = X_train.dropna()\n",
    "X_test = X_test.dropna()\n",
    "y_train = y_train.dropna()\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41665, 17), (13822, 17), (41665,), (13822,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to reshape before encoding data\n",
    "# Need X_train and y_train to have same shape[0]\n",
    "# Also need X_test and y_test to have same?\n",
    "\n",
    "y_train_random_sample = np.random.choice(y_train.index.values, 41665)\n",
    "sampled_y_train = y_train.loc[y_train_random_sample]\n",
    "y_test_random_sample = np.random.choice(y_test.index.values, 13822)\n",
    "sampled_y_test = y_test.loc[y_test_random_sample]\n",
    "\n",
    "X_train.shape, X_test.shape, sampled_y_train.shape, sampled_y_test.shape\n",
    "\n",
    "# test_pred_proba = gb.predict_proba(test)[:,1]\n",
    "# print('Validation ROC AUC:', roc_auc_score(test, test_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder()\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Modeling\n",
    "\n",
    "Fit a Random Forest or Gradient Boosting model with the train set. (You may use scikit-learn, xgboost, or any other library.) Use cross-validation to estimate an ROC AUC validation score.\n",
    "\n",
    "Use your model to predict probabilities for the test set. Get an ROC AUC test score >= 0.60.\n",
    "\n",
    "_To earn a score of 3 for this part, get an ROC AUC test score >= 0.70._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First work is for baseline modeling\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49449246, 0.49003441, 0.48145368, 0.49692797, 0.47023361])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With reshaping done, fit model, then compute cross_val_score\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, sampled_y_train)\n",
    "cross_val_score(gb, X_test, sampled_y_test, scoring='roc_auc', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Visualization\n",
    "\n",
    "Make one visualization for model interpretation. (You may use any libraries.) Choose one of these types:\n",
    "- Feature Importances\n",
    "- Permutation Importances\n",
    "- Partial Dependence Plot\n",
    "\n",
    "_To earn a score of 3 for this part, make at least two of these visualization types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
