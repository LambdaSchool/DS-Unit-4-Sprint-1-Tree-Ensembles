{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 157k/157k [00:00<00:00, 82.0kB/s]\n",
      "Successfully submitted to DS1 Tree EnsemblesCPU times: user 1min 6s, sys: 898 ms, total: 1min 7s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "\n",
    "def clean(dat: pd.DataFrame) -> pd.DataFrame: \n",
    "    ''' refactored Ryan H's wrangle function from lecture today into method chaining'''\n",
    "    greater_than_10k_ = [k for k,v in dat.mean().iteritems() if v > 10**4]\n",
    "\n",
    "    todrop_ = ['id', # id is random\n",
    "              'member_id', # all null\n",
    "              'url', # all null\n",
    "              'desc', # all null\n",
    "              'title', # duplicate of purpose\n",
    "              'grade', # duplicate of sub_grade\n",
    "              'emp_title', # getting re-engineered, cardinality too high\n",
    "              'zip_code' # cardinality too high\n",
    "               # list `greater_than_10k` will be engineered into units of k\n",
    "             ] \n",
    "\n",
    "    many_nulls = ['sec_app_mths_since_last_major_derog',\n",
    "                  'sec_app_revol_util',\n",
    "                  'sec_app_earliest_cr_line',\n",
    "                  'sec_app_mort_acc',\n",
    "                  'dti_joint',\n",
    "                  'sec_app_collections_12_mths_ex_med',\n",
    "                  'sec_app_chargeoff_within_12_mths',\n",
    "                  'sec_app_num_rev_accts',\n",
    "                  'sec_app_open_act_il',\n",
    "                  'sec_app_open_acc',\n",
    "                  'revol_bal_joint',\n",
    "                  'annual_inc_joint',\n",
    "                  'sec_app_inq_last_6mths',\n",
    "                  'mths_since_last_record',\n",
    "                  'mths_since_recent_bc_dlq',\n",
    "                  'mths_since_last_major_derog',\n",
    "                  'mths_since_recent_revol_delinq',\n",
    "                  'mths_since_last_delinq',\n",
    "                  'il_util',\n",
    "                  'emp_length',\n",
    "                  'mths_since_recent_inq',\n",
    "                  'mo_sin_old_il_acct',\n",
    "                  'mths_since_rcnt_il',\n",
    "                  'num_tl_120dpd_2m',\n",
    "                  'bc_util',\n",
    "                  'percent_bc_gt_75',\n",
    "                  'bc_open_to_buy',\n",
    "                  'mths_since_recent_bc']\n",
    "\n",
    "    greater_than_10k = [i for i in greater_than_10k_ if i not in many_nulls]\n",
    "\n",
    "    todrop = [i for i in todrop_ if i not in many_nulls] + greater_than_10k\n",
    "    \n",
    "    def wrangle_sub_grade(x):\n",
    "        '''Transform sub_grade from \"A1\" - \"G5\" to 1.1 - 7.5'''\n",
    "        first_digit = ord(x[0]) - 64\n",
    "        second_digit = int(x[1])\n",
    "        return first_digit + second_digit/10\n",
    "    \n",
    "    assigns = {# sub_grade to ordinal\n",
    "        **{'sub_grade': dat.sub_grade.apply(wrangle_sub_grade)}, # sub_grade to ordinal\n",
    "        # Convert percentages from strings to floats\n",
    "        **{name: dat[name].str.strip('%').astype(float) \n",
    "                 for name in ['int_rate', 'revol_util']}, # Convert percentages from strings to floats\n",
    "        # Transform earliest_cr_line to an integer: how many days it's been open\n",
    "        **{'earliest_cr_line': (pd.Timestamp.today() - \\\n",
    "                                  pd.to_datetime(dat.earliest_cr_line, infer_datetime_format=True)\n",
    "                               ).dt.days},  \n",
    "        # Create features for three employee titles: teacher, manager, owner\n",
    "        **{'emp_title_'+name: dat.emp_title.str.contains(name, na=False) \n",
    "                              for name in ['teacher', 'manager', 'owner']},\n",
    "        # Transform features with many nulls to binary flags\n",
    "        **{name: dat[name].isnull() for name in many_nulls},\n",
    "        # For features with few nulls, do mean imputation\n",
    "        **{name: dat[name].fillna(dat[name].mean()) for name in dat.select_dtypes(include=['int', 'float', 'float64']).columns}\n",
    "              }\n",
    "    \n",
    "    return (dat.assign(emp_title = dat.emp_title.str.lower())\n",
    "               .assign(**assigns)\n",
    "               #.assign(revol_util = dat.revol_util.fillna(dat.revol_util.mean()))\n",
    "               .drop(todrop, axis=1)), dat.id.values\n",
    "    \n",
    "# df = clean(pd.read_csv('train_features.csv').sample(5000))[0]\n",
    "# # inscrutably, it is completely necessary to do this here. it doesn't get caught in above code (it should). \n",
    "# df.revol_util = df.revol_util.fillna(df.revol_util.mean())\n",
    "\n",
    "# assert df.isna().sum().sum()==0\n",
    "\n",
    "# cats = list(df.select_dtypes(include=['object']).columns)\n",
    "# nums = list(df.select_dtypes(exclude=['object']).columns)\n",
    "\n",
    "def encode(encoder, trainpath = 'train_features.csv', testpath = 'test_features.csv'): \n",
    "    ''' pass a fresh encoder instance from ce library. '''\n",
    "\n",
    "    df_test = clean(pd.read_csv(testpath))\n",
    "    X_train = encoder.fit_transform(clean(pd.read_csv(trainpath))[0])\n",
    "    X_test = encoder.fit_transform(df_test[0])\n",
    "    return {'train': X_train, 'test': X_test, 'TEST_IDs': df_test[1]}\n",
    "\n",
    "dfs = encode(ce.BinaryEncoder())\n",
    "\n",
    "y_train = pd.read_csv('train_labels.csv')['charged_off']\n",
    "\n",
    "dtrain = xgb.DMatrix(dfs['train'].values, y_train.values)\n",
    "dtest = xgb.DMatrix(dfs['test'].values)\n",
    "\n",
    "\n",
    "# specify parameters via map\n",
    "param = {'booster': 'dart',\n",
    "         'max_depth': 5, 'learning_rate': 0.1,\n",
    "         'objective': 'binary:logistic', 'silent': True,\n",
    "         'sample_type': 'uniform',\n",
    "         'normalize_type': 'tree',\n",
    "         'rate_drop': 0.1,\n",
    "         'skip_drop': 0.5}\n",
    "num_round = 50\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "# make prediction\n",
    "# ntree_limit must not be 0\n",
    "preds = bst.predict(dtest, ntree_limit=num_round)\n",
    "\n",
    "preds_df = pd.DataFrame({'id': dfs['TEST_IDs'], 'charged_off': preds})\n",
    "\n",
    "assert all([x==y for x,y in zip(pd.read_csv('test_features.csv').id, preds_df.id)]) #sample_submission.index\n",
    "\n",
    "def write_submit(submit_df, name='submission.csv'): \n",
    "    ''''''\n",
    "    submit_df.to_csv(name, index=False)\n",
    "    \n",
    "    !kaggle competitions submit -c ds1-tree-ensembles -f submission.csv -m \"Basic XGBoost \"\n",
    "    return submit_df\n",
    "\n",
    "write_submit(preds_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
