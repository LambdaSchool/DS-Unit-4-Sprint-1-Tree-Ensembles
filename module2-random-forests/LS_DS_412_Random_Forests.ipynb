{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lambda School Data Science — Tree Ensembles_ \n",
    "\n",
    "# Random Forests\n",
    "\n",
    "### Pre-read / pre-watch\n",
    "- [Scikit-Learn User Guide, Ensemble Methods](https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "- [Coloring with Random Forests](http://structuringtheunstructured.blogspot.com/2017/11/coloring-with-random-forests.html)\n",
    "- [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "### More\n",
    "- [Machine Learning Explainability: Permutation Importance](https://www.kaggle.com/dansbecker/permutation-importance)\n",
    "- [eli5: Permutation Importance](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
    "- [eli5: Explaining XGBoost predictions on the Titanic dataset](https://eli5.readthedocs.io/en/latest/_notebooks/xgboost-titanic.html)\n",
    "- [The Mechanics of Machine Learning: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
    "\n",
    "\n",
    "[Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    ">There are a few things to keep in mind when using the impurity based ranking. Firstly, feature selection based on impurity reduction is biased towards preferring variables with more categories. \n",
    ">\n",
    ">Secondly, when the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others. But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable.\n",
    "\n",
    "\n",
    "[An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/), Chapter 8.2.1, Out-of-Bag Error Estimation\n",
    "\n",
    "> It turns out that **there is a very straightforward way to estimate the test error of a bagged model, without the need to perform cross-validation or the validation set approach.** \n",
    ">\n",
    "> Recall that the key to bagging is that trees are repeatedly fit to bootstrapped subsets of the observations. One can show that on average, each bagged tree makes use of around two-thirds of the observations. The remaining one-third of the **observations not used to fit a given bagged tree are referred to as the out-of bag (OOB) observations.**\n",
    ">\n",
    ">We can predict the response for the ith observation using each of the trees in which that observation was OOB. This will yield around B/3 predictions for the ith observation. In order to obtain a single prediction for the ith observation, we can average these predicted responses (if regression is the goal) or can take a majority vote (if classification is the goal). \n",
    ">\n",
    ">This leads to a single OOB prediction for the ith observation. An OOB prediction can be obtained in this way for each of the n observations, from which the overall OOB MSE (for a regression problem) or classification error (for a classification problem) can be computed. The resulting **OOB error is a valid estimate of the test error for the bagged model, since the response for each observation is predicted using only the trees that were not fit using that observation.** ... \n",
    ">\n",
    ">It can be shown that with B sufficiently large, OOB error is virtually equivalent to leave-one-out cross-validation error. The OOB approach for estimating the test error is particularly **convenient when performing bagging on large data sets for which cross-validation would be computationally onerous.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "- [eli5](https://github.com/TeamHG-Memex/eli5): `conda install -c conda-forge eli5` / `pip install eli5`\n",
    "- [category_encoders](https://github.com/scikit-learn-contrib/categorical-encoding): `conda install -c conda-forge category_encoders` / `pip install category_encoders`\n",
    "- [mlxtend](https://github.com/rasbt/mlxtend): `pip install mlxtend`\n",
    "- [ipywidgets](https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html): included with Anaconda, doesn't work on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipywidgets revisited: Decision Tree vs Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressing a wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c49fa6200cd48efa1d72f26ea3f04e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='max_depth', max=8, min=1), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Example from http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html\n",
    "def make_data():\n",
    "    import numpy as np\n",
    "    rng = np.random.RandomState(1)\n",
    "    X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "    y = np.sin(X).ravel()\n",
    "    y[::5] += 2 * (0.5 - rng.rand(16))\n",
    "    return X, y\n",
    "\n",
    "X, y = make_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "def regress_wave(max_depth):\n",
    "    dt = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    dt.fit(X_train, y_train)\n",
    "    print('Decision Tree train R^2:', dt.score(X_train, y_train))\n",
    "    print('Decision Tree test R^2:', dt.score(X_test, y_test))\n",
    "    plt.scatter(X_train, y_train)\n",
    "    plt.scatter(X_test, y_test)\n",
    "    plt.step(X, dt.predict(X))\n",
    "    plt.show()\n",
    "    \n",
    "    rf = RandomForestRegressor(max_depth=max_depth, n_estimators=100, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print('Random Forest train R^2:', rf.score(X_train, y_train))\n",
    "    print('Random Forest test R^2:', rf.score(X_test, y_test))\n",
    "    plt.scatter(X_train, y_train)\n",
    "    plt.scatter(X_test, y_test)\n",
    "    plt.step(X, rf.predict(X))\n",
    "    plt.show()\n",
    "    \n",
    "interact(regress_wave, max_depth=(1,8,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic survival, by Age & Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f151c00802455881342af50907d0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='max_depth', max=8, min=1), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "X = SimpleImputer().fit_transform(titanic[['age', 'fare']])\n",
    "y = titanic['survived'].values\n",
    "\n",
    "def classify_titanic(max_depth):\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    dt.fit(X, y)\n",
    "    plot_decision_regions(X, y, dt)\n",
    "    plt.title('Decision Tree')\n",
    "    plt.axis((0,75,0,175))\n",
    "    plt.show()\n",
    "\n",
    "    rf = RandomForestClassifier(max_depth=max_depth, n_estimators=100, n_jobs=-1)\n",
    "    rf.fit(X, y)\n",
    "    plot_decision_regions(X, y, rf)\n",
    "    plt.title('Random Forest')\n",
    "    plt.axis((0,75,0,175))\n",
    "    plt.show()\n",
    "    \n",
    "interact(classify_titanic, max_depth=(1,8,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv files downloaded from [Kaggle](https://www.kaggle.com/c/ds1-tree-ensembles/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37745, 103), (9437, 103), (37745,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "X_train = pd.read_csv('../ds1-tree-ensembles/train_features.csv')\n",
    "X_test = pd.read_csv('../ds1-tree-ensembles/test_features.csv')\n",
    "y_train = pd.read_csv('../ds1-tree-ensembles/train_labels.csv')['charged_off']\n",
    "sample_submission = pd.read_csv('../ds1-tree-ensembles/sample_submission.csv')\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangle X_train and X_test in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37745, 98), (9437, 98))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Drop some columns\n",
    "    X = X.drop(columns='id')  # id is random\n",
    "    X = X.drop(columns=['member_id', 'url', 'desc'])  # All null\n",
    "    X = X.drop(columns='title')  # Duplicative of purpose\n",
    "    X = X.drop(columns='grade')  # Duplicative of sub_grade\n",
    "    \n",
    "    # Transform sub_grade from \"A1\" - \"G5\" to 1.1 - 7.5\n",
    "    def wrangle_sub_grade(x):\n",
    "        first_digit = ord(x[0]) - 64\n",
    "        second_digit = int(x[1])\n",
    "        return first_digit + second_digit/10\n",
    "    \n",
    "    X['sub_grade'] = X['sub_grade'].apply(wrangle_sub_grade)\n",
    "\n",
    "    # Convert percentages from strings to floats\n",
    "    X['int_rate'] = X['int_rate'].str.strip('%').astype(float)\n",
    "    X['revol_util'] = X['revol_util'].str.strip('%').astype(float)\n",
    "        \n",
    "    # Transform earliest_cr_line to an integer: how many days it's been open\n",
    "    X['earliest_cr_line'] = pd.to_datetime(X['earliest_cr_line'], infer_datetime_format=True) # `infer_datetime_format=True` makes it go faster\n",
    "    X['earliest_cr_line'] = pd.Timestamp.today() - X['earliest_cr_line'] # (difference from today to when credit line was opened) how long the credit line have been opened\n",
    "    X['earliest_cr_line'] = X['earliest_cr_line'].dt.days # .dt accessor is very useful to get 'days' or 'months'... \n",
    "    # if you get the 'months' (which are from 1 to 12) you can categorically or ordinally encode that\n",
    "    \n",
    "    # Create features for three employee titles: teacher, manager, owner\n",
    "    # most common job titles\n",
    "    # some titles are repeated with lower or upper case\n",
    "    X['emp_title'] = X['emp_title'].str.lower()\n",
    "    X['emp_title_teacher'] = X['emp_title'].str.contains('teacher', na=False)\n",
    "    X['emp_title_manager'] = X['emp_title'].str.contains('manager', na=False)\n",
    "    X['emp_title_owner']   = X['emp_title'].str.contains('owner', na=False)\n",
    "    \n",
    "    # Drop categoricals with high cardinality\n",
    "    X = X.drop(columns=['emp_title', 'zip_code'])\n",
    "    \n",
    "    # Transform features with many nulls to binary flags\n",
    "    many_nulls = ['sec_app_mths_since_last_major_derog',\n",
    "                  'sec_app_revol_util',\n",
    "                  'sec_app_earliest_cr_line',\n",
    "                  'sec_app_mort_acc',\n",
    "                  'dti_joint',\n",
    "                  'sec_app_collections_12_mths_ex_med',\n",
    "                  'sec_app_chargeoff_within_12_mths',\n",
    "                  'sec_app_num_rev_accts',\n",
    "                  'sec_app_open_act_il',\n",
    "                  'sec_app_open_acc',\n",
    "                  'revol_bal_joint',\n",
    "                  'annual_inc_joint',\n",
    "                  'sec_app_inq_last_6mths',\n",
    "                  'mths_since_last_record',\n",
    "                  'mths_since_recent_bc_dlq',\n",
    "                  'mths_since_last_major_derog',\n",
    "                  'mths_since_recent_revol_delinq',\n",
    "                  'mths_since_last_delinq',\n",
    "                  'il_util',\n",
    "                  'emp_length',\n",
    "                  'mths_since_recent_inq',\n",
    "                  'mo_sin_old_il_acct',\n",
    "                  'mths_since_rcnt_il',\n",
    "                  'num_tl_120dpd_2m',\n",
    "                  'bc_util',\n",
    "                  'percent_bc_gt_75',\n",
    "                  'bc_open_to_buy',\n",
    "                  'mths_since_recent_bc']\n",
    "\n",
    "    for col in many_nulls:\n",
    "        X[col] = X[col].isnull()\n",
    "    \n",
    "    # For features with few nulls, do mean imputation\n",
    "    for col in X:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col] = X[col].fillna(X[col].mean())\n",
    "    \n",
    "    # Return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train = wrangle(X_train)\n",
    "X_test  = wrangle(X_test)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>application_type</th>\n",
       "      <th>annual_inc_joint</th>\n",
       "      <th>dti_joint</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>open_acc_6m</th>\n",
       "      <th>open_act_il</th>\n",
       "      <th>open_il_12m</th>\n",
       "      <th>open_il_24m</th>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>bc_open_to_buy</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_tl</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>mths_since_recent_bc</th>\n",
       "      <th>mths_since_recent_bc_dlq</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>mths_since_recent_revol_delinq</th>\n",
       "      <th>num_accts_ever_120_pd</th>\n",
       "      <th>num_actv_bc_tl</th>\n",
       "      <th>num_actv_rev_tl</th>\n",
       "      <th>num_bc_sats</th>\n",
       "      <th>num_bc_tl</th>\n",
       "      <th>num_il_tl</th>\n",
       "      <th>num_op_rev_tl</th>\n",
       "      <th>num_rev_accts</th>\n",
       "      <th>num_rev_tl_bal_gt_0</th>\n",
       "      <th>num_sats</th>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>revol_bal_joint</th>\n",
       "      <th>sec_app_earliest_cr_line</th>\n",
       "      <th>sec_app_inq_last_6mths</th>\n",
       "      <th>sec_app_mort_acc</th>\n",
       "      <th>sec_app_open_acc</th>\n",
       "      <th>sec_app_revol_util</th>\n",
       "      <th>sec_app_open_act_il</th>\n",
       "      <th>sec_app_num_rev_accts</th>\n",
       "      <th>sec_app_chargeoff_within_12_mths</th>\n",
       "      <th>sec_app_collections_12_mths_ex_med</th>\n",
       "      <th>sec_app_mths_since_last_major_derog</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>emp_title_teacher</th>\n",
       "      <th>emp_title_manager</th>\n",
       "      <th>emp_title_owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>16.02</td>\n",
       "      <td>422.01</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NC</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0</td>\n",
       "      <td>4856</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4912</td>\n",
       "      <td>23.5</td>\n",
       "      <td>15</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Individual</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174783</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>33668</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2962</td>\n",
       "      <td>63.0</td>\n",
       "      <td>20900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>24969.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>92.9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206618</td>\n",
       "      <td>38580</td>\n",
       "      <td>5500</td>\n",
       "      <td>40863</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Cash</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6300</td>\n",
       "      <td>6300</td>\n",
       "      <td>36 months</td>\n",
       "      <td>14.07</td>\n",
       "      <td>215.54</td>\n",
       "      <td>3.3</td>\n",
       "      <td>False</td>\n",
       "      <td>RENT</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>CA</td>\n",
       "      <td>21.42</td>\n",
       "      <td>0</td>\n",
       "      <td>2574</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>11876</td>\n",
       "      <td>59.4</td>\n",
       "      <td>12</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Individual</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>19170</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5153</td>\n",
       "      <td>72.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3105.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43140</td>\n",
       "      <td>31046</td>\n",
       "      <td>16900</td>\n",
       "      <td>23140</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Cash</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.21</td>\n",
       "      <td>139.38</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>RENT</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>CA</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0</td>\n",
       "      <td>6896</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1715</td>\n",
       "      <td>5.2</td>\n",
       "      <td>19</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Individual</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35329</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>33614</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1196</td>\n",
       "      <td>54.0</td>\n",
       "      <td>33300</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2718.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>218</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65092</td>\n",
       "      <td>35329</td>\n",
       "      <td>23300</td>\n",
       "      <td>31792</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Cash</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>9.44</td>\n",
       "      <td>384.06</td>\n",
       "      <td>2.1</td>\n",
       "      <td>False</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>OH</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0</td>\n",
       "      <td>5890</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>9404</td>\n",
       "      <td>16.3</td>\n",
       "      <td>33</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Individual</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75160</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>17123</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6898</td>\n",
       "      <td>32.0</td>\n",
       "      <td>57600</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3579.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133065</td>\n",
       "      <td>26527</td>\n",
       "      <td>40500</td>\n",
       "      <td>25465</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Cash</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>22.35</td>\n",
       "      <td>460.47</td>\n",
       "      <td>4.5</td>\n",
       "      <td>False</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>TX</td>\n",
       "      <td>14.04</td>\n",
       "      <td>4</td>\n",
       "      <td>6347</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>17895</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Individual</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>7218</td>\n",
       "      <td>113702</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>16711</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5373</td>\n",
       "      <td>35.0</td>\n",
       "      <td>73900</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>6317.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>82.2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192842</td>\n",
       "      <td>34606</td>\n",
       "      <td>43300</td>\n",
       "      <td>24499</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Cash</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt        term  int_rate  installment  sub_grade  \\\n",
       "0      12000        12000   36 months     16.02       422.01        3.5   \n",
       "1       6300         6300   36 months     14.07       215.54        3.3   \n",
       "2       4500         4500   36 months      7.21       139.38        1.3   \n",
       "3      12000        12000   36 months      9.44       384.06        2.1   \n",
       "4      12000        12000   36 months     22.35       460.47        4.5   \n",
       "\n",
       "   emp_length home_ownership  annual_inc             purpose addr_state  \\\n",
       "0       False       MORTGAGE     81000.0  debt_consolidation         NC   \n",
       "1       False           RENT     39000.0  debt_consolidation         CA   \n",
       "2       False           RENT     78000.0  debt_consolidation         CA   \n",
       "3       False       MORTGAGE     62000.0  debt_consolidation         OH   \n",
       "4       False       MORTGAGE     70000.0  debt_consolidation         TX   \n",
       "\n",
       "     dti  delinq_2yrs  earliest_cr_line  inq_last_6mths  \\\n",
       "0  12.76            0              4856               1   \n",
       "1  21.42            0              2574               1   \n",
       "2   2.17            0              6896               2   \n",
       "3  13.76            0              5890               0   \n",
       "4  14.04            4              6347               2   \n",
       "\n",
       "   mths_since_last_delinq  mths_since_last_record  open_acc  pub_rec  \\\n",
       "0                   False                    True         7        0   \n",
       "1                    True                    True        10        0   \n",
       "2                    True                    True        13        0   \n",
       "3                    True                    True        22        0   \n",
       "4                   False                    True        18        0   \n",
       "\n",
       "   revol_bal  revol_util  total_acc initial_list_status  \\\n",
       "0       4912        23.5         15                   w   \n",
       "1      11876        59.4         12                   w   \n",
       "2       1715         5.2         19                   w   \n",
       "3       9404        16.3         33                   w   \n",
       "4      17895        24.2         45                   w   \n",
       "\n",
       "   collections_12_mths_ex_med  mths_since_last_major_derog application_type  \\\n",
       "0                           0                        False       Individual   \n",
       "1                           0                         True       Individual   \n",
       "2                           0                         True       Individual   \n",
       "3                           0                         True       Individual   \n",
       "4                           0                        False       Individual   \n",
       "\n",
       "   annual_inc_joint  dti_joint  acc_now_delinq  tot_coll_amt  tot_cur_bal  \\\n",
       "0              True       True               0             0       174783   \n",
       "1              True       True               0             0        31046   \n",
       "2              True       True               0             0        35329   \n",
       "3              True       True               0             0        75160   \n",
       "4              True       True               0          7218       113702   \n",
       "\n",
       "   open_acc_6m  open_act_il  open_il_12m  open_il_24m  mths_since_rcnt_il  \\\n",
       "0            1            2            0            4               False   \n",
       "1            0            1            0            2               False   \n",
       "2            0            8            1            2               False   \n",
       "3            4            1            0            2               False   \n",
       "4            9            2            2            4               False   \n",
       "\n",
       "   total_bal_il  il_util  open_rv_12m  open_rv_24m  max_bal_bc  all_util  \\\n",
       "0         33668    False            2            5        2962      63.0   \n",
       "1         19170    False            3            8        5153      72.0   \n",
       "2         33614    False            1            1        1196      54.0   \n",
       "3         17123    False            6            9        6898      32.0   \n",
       "4         16711    False            9           10        5373      35.0   \n",
       "\n",
       "   total_rev_hi_lim  inq_fi  total_cu_tl  inq_last_12m  acc_open_past_24mths  \\\n",
       "0             20900       1            1             2                     9   \n",
       "1             20000       1            0             1                    10   \n",
       "2             33300       4            0             3                     3   \n",
       "3             57600       3            1             2                    12   \n",
       "4             73900       3            6             3                    14   \n",
       "\n",
       "   avg_cur_bal  bc_open_to_buy  bc_util  chargeoff_within_12_mths  \\\n",
       "0      24969.0           False    False                         0   \n",
       "1       3105.0           False    False                         0   \n",
       "2       2718.0           False    False                         0   \n",
       "3       3579.0           False    False                         0   \n",
       "4       6317.0           False    False                         0   \n",
       "\n",
       "   delinq_amnt  mo_sin_old_il_acct  mo_sin_old_rev_tl_op  \\\n",
       "0            0               False                    23   \n",
       "1            0               False                    72   \n",
       "2            0               False                   218   \n",
       "3            0               False                   179   \n",
       "4            0               False                   201   \n",
       "\n",
       "   mo_sin_rcnt_rev_tl_op  mo_sin_rcnt_tl  mort_acc  mths_since_recent_bc  \\\n",
       "0                      1               1         1                 False   \n",
       "1                      8               8         0                 False   \n",
       "2                     10              10         0                 False   \n",
       "3                      1               1         1                 False   \n",
       "4                      0               0         1                 False   \n",
       "\n",
       "   mths_since_recent_bc_dlq  mths_since_recent_inq  \\\n",
       "0                      True                  False   \n",
       "1                      True                  False   \n",
       "2                      True                  False   \n",
       "3                      True                  False   \n",
       "4                     False                  False   \n",
       "\n",
       "   mths_since_recent_revol_delinq  num_accts_ever_120_pd  num_actv_bc_tl  \\\n",
       "0                            True                      2               2   \n",
       "1                            True                      0               6   \n",
       "2                            True                      0               3   \n",
       "3                            True                      0               1   \n",
       "4                           False                      6               9   \n",
       "\n",
       "   num_actv_rev_tl  num_bc_sats  num_bc_tl  num_il_tl  num_op_rev_tl  \\\n",
       "0                2            2          2          9              4   \n",
       "1                7            7          8          2              9   \n",
       "2                3            3          4         13              5   \n",
       "3                3            9         13          7             20   \n",
       "4               11           11         14         22             15   \n",
       "\n",
       "   num_rev_accts  num_rev_tl_bal_gt_0  num_sats  num_tl_120dpd_2m  \\\n",
       "0              5                    2         7             False   \n",
       "1             10                    7        10             False   \n",
       "2              6                    3        13             False   \n",
       "3             25                    3        22             False   \n",
       "4             20                   11        18             False   \n",
       "\n",
       "   num_tl_30dpd  num_tl_90g_dpd_24m  num_tl_op_past_12m  pct_tl_nvr_dlq  \\\n",
       "0             0                   0                   2            92.9   \n",
       "1             0                   0                   3           100.0   \n",
       "2             0                   0                   2           100.0   \n",
       "3             0                   0                   7           100.0   \n",
       "4             0                   2                  11            82.2   \n",
       "\n",
       "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
       "0             False                     0          0           206618   \n",
       "1             False                     0          0            43140   \n",
       "2             False                     0          0            65092   \n",
       "3             False                     0          0           133065   \n",
       "4             False                     0          0           192842   \n",
       "\n",
       "   total_bal_ex_mort  total_bc_limit  total_il_high_credit_limit  \\\n",
       "0              38580            5500                       40863   \n",
       "1              31046           16900                       23140   \n",
       "2              35329           23300                       31792   \n",
       "3              26527           40500                       25465   \n",
       "4              34606           43300                       24499   \n",
       "\n",
       "   revol_bal_joint  sec_app_earliest_cr_line  sec_app_inq_last_6mths  \\\n",
       "0             True                      True                    True   \n",
       "1             True                      True                    True   \n",
       "2             True                      True                    True   \n",
       "3             True                      True                    True   \n",
       "4             True                      True                    True   \n",
       "\n",
       "   sec_app_mort_acc  sec_app_open_acc  sec_app_revol_util  \\\n",
       "0              True              True                True   \n",
       "1              True              True                True   \n",
       "2              True              True                True   \n",
       "3              True              True                True   \n",
       "4              True              True                True   \n",
       "\n",
       "   sec_app_open_act_il  sec_app_num_rev_accts  \\\n",
       "0                 True                   True   \n",
       "1                 True                   True   \n",
       "2                 True                   True   \n",
       "3                 True                   True   \n",
       "4                 True                   True   \n",
       "\n",
       "   sec_app_chargeoff_within_12_mths  sec_app_collections_12_mths_ex_med  \\\n",
       "0                              True                                True   \n",
       "1                              True                                True   \n",
       "2                              True                                True   \n",
       "3                              True                                True   \n",
       "4                              True                                True   \n",
       "\n",
       "   sec_app_mths_since_last_major_derog disbursement_method  emp_title_teacher  \\\n",
       "0                                 True                Cash              False   \n",
       "1                                 True                Cash              False   \n",
       "2                                 True                Cash              False   \n",
       "3                                 True                Cash              False   \n",
       "4                                 True                Cash              False   \n",
       "\n",
       "   emp_title_manager  emp_title_owner  \n",
       "0              False            False  \n",
       "1              False            False  \n",
       "2              False            False  \n",
       "3              False            False  \n",
       "4              False            False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now X_train (and X_test) have no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = X_train.isnull().sum()\n",
    "all(null_counts == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And no high cardinality categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality = X_train.select_dtypes(exclude='number').nunique()\n",
    "all(cardinality <= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70297128, 0.70044849, 0.69332495, 0.68879982, 0.68917646])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    DecisionTreeClassifier(max_depth=5, class_weight='balanced')\n",
    ")\n",
    "\n",
    "cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Improves ROC AUC compared to Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.7266742981178068, total=   6.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7275840818005378, total=   3.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7217624371943251, total=   3.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   13.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7293195302754879, total=   3.4s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7366618249190476, total=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   21.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   21.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7266743 , 0.72758408, 0.72176244, 0.72931953, 0.73666182])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        class_weight='balanced', \n",
    "        min_samples_leaf=0.005, # not going below half of percentage of the population -- min_samples_leaf = 1 can lead to overfitting\n",
    "        oob_score=True, \n",
    "        n_jobs=-1)\n",
    ")\n",
    "\n",
    "cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc', verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Bag estimated score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-bag is a faster way to get an estimated score with Random Forest, using the parameter `oob_score=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC, Out-of-Bag estimate: 0.7267958273944365\n",
      "Wall time: 4.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred_proba = pipe.named_steps['randomforestclassifier'].oob_decision_function_[:, 1]\n",
    "print('ROC AUC, Out-of-Bag estimate:', roc_auc_score(y_train, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 2\n",
      "ROC AUC, OOB: 0.698732981136057\n",
      "Max Depth: 4\n",
      "ROC AUC, OOB: 0.7164431886661544\n",
      "Max Depth: 6\n",
      "ROC AUC, OOB: 0.723005176375296\n",
      "Max Depth: 8\n",
      "ROC AUC, OOB: 0.7260228092345867\n",
      "Max Depth: 10\n",
      "ROC AUC, OOB: 0.7221229231936177\n",
      "Max Depth: None\n",
      "ROC AUC, OOB: 0.7068857730663173\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_depths = list(range(2, 12, 2)) + [None]\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    \n",
    "    pipe = make_pipeline(\n",
    "        ce.OrdinalEncoder(), \n",
    "        RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            class_weight='balanced', \n",
    "            max_depth=max_depth, \n",
    "            oob_score=True, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_proba = pipe.named_steps['randomforestclassifier'].oob_decision_function_[:, 1]\n",
    "    print('Max Depth:', max_depth)\n",
    "    print('ROC AUC, OOB:', roc_auc_score(y_train, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at feature importances. [But remember:](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "\n",
    ">Firstly, feature selection based on impurity reduction is biased towards preferring variables with more categories.\n",
    ">\n",
    ">Secondly, when the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_feature_importances(\n",
    "    pipe, X, y, estimator_name='randomforestclassifier', \n",
    "    n=20, figsize=(8, 8)):\n",
    "    \n",
    "    # pipe must not change dimensions of X dataframe\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    importances = pd.Series(\n",
    "        pipe.named_steps[estimator_name].feature_importances_, \n",
    "        X.columns)\n",
    "\n",
    "    top_n = importances.sort_values(ascending=False)[:n]\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    top_n.sort_values().plot.barh(color='grey')\n",
    "\n",
    "    \n",
    "show_feature_importances(pipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Column Importance / \"Ablation Study\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sub_grade` and `int_rate` are highly correlated. If we drop one of those features, the model uses the other more, so the score remains similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipe, X_train.drop(columns='sub_grade'), y_train, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_importances(pipe, X_train.drop(columns='sub_grade'), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we drop _both_ features, then the score decreases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipe, X_train.drop(columns=['sub_grade', 'int_rate']), y_train, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, see [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation Importance is a compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
    "\n",
    "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
    "\n",
    "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
    ">\n",
    "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
    ">\n",
    ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
    ">\n",
    ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise.\n",
    "\n",
    "For more documentation on using this library, see:\n",
    "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
    "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_transformed = encoder.fit_transform(X_train)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    class_weight='balanced', \n",
    "    min_samples_leaf=0.005, \n",
    "    n_jobs=-1)\n",
    "\n",
    "model.fit(X_train_transformed, y_train)\n",
    "permuter = PermutationImportance(model, scoring='roc_auc', n_iter=1, cv='prefit')\n",
    "permuter.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(permuter, top=None, feature_names=X_train_transformed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Permutation Importance weights for feature selection. For example, we can remove features with zero weight. The model trains faster and the score does not decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = X_train.columns[permuter.feature_importances_ > 0]\n",
    "cross_val_score(pipe, X_train[subset], y_train, cv=5, scoring='roc_auc', verbose=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
