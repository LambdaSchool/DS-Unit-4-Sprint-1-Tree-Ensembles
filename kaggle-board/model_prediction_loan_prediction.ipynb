{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/d3/82a4b85a87ece114f6d0139d643580c726efa45fa4db3b81aed38c0156c5/category_encoders-1.3.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 14.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (1.15.4)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (0.19.1)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: pandas>=0.20.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (0.22.0)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.20.1->category_encoders) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.20.1->category_encoders) (2.7.3)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-1.3.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eli5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/2b/246db9e1c2d6f38e999daf0c4d5e54f36fbd0b937ffb13a34d32c2139403/eli5-0.8.2-py2.py3-none-any.whl (98kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 19.4MB/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (1.11.0)\n",
      "Collecting tabulate>=0.7.7 (from eli5)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 25.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>16.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (18.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (1.15.4)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (0.19.1)\n",
      "Requirement already satisfied: typing in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (3.6.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (1.1.0)\n",
      "Collecting graphviz (from eli5)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (2.10)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jinja2->eli5) (1.0)\n",
      "Building wheels for collected packages: tabulate\n",
      "  Running setup.py bdist_wheel for tabulate ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "Successfully built tabulate\n",
      "Installing collected packages: tabulate, graphviz, eli5\n",
      "Successfully installed eli5-0.8.2 graphviz-0.10.1 tabulate-0.8.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 1.93 s, total: 19.2 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "X_train = pd.read_csv('data/train_features.csv')\n",
    "X_test = pd.read_csv('data/test_features.csv')\n",
    "y_train = pd.read_csv('data/train_labels.csv')['charged_off']\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((40000, 103), (1269457, 103), (40000,), (1269457,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, train_size=40000, \n",
    "    random_state=42, stratify=y_train)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 11.3 s, total: 1min 22s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Drop some columns\n",
    "    X = X.drop(columns='id')  # id is random\n",
    "    X = X.drop(columns=['member_id', 'url', 'desc'])  # All null\n",
    "    X = X.drop(columns='title')  # Duplicative of purpose\n",
    "    X = X.drop(columns='grade')  # Duplicative of sub_grade\n",
    "    \n",
    "    # Transform sub_grade from \"A1\" - \"G5\" to 1.1 - 7.5\n",
    "    def wrangle_sub_grade(x):\n",
    "        first_digit = ord(x[0]) - 64\n",
    "        second_digit = int(x[1])\n",
    "        return first_digit + second_digit/10\n",
    "    \n",
    "    X['sub_grade'] = X['sub_grade'].apply(wrangle_sub_grade)\n",
    "\n",
    "    # Convert percentages from strings to floats\n",
    "    X['int_rate'] = X['int_rate'].str.strip('%').astype(float)\n",
    "    X['revol_util'] = X['revol_util'].str.strip('%').astype(float)\n",
    "        \n",
    "    # Transform earliest_cr_line to an integer: how many days it's been open\n",
    "    X['earliest_cr_line'] = pd.to_datetime(X['earliest_cr_line'], infer_datetime_format=True)\n",
    "    X['earliest_cr_line'] = pd.Timestamp.today() - X['earliest_cr_line']\n",
    "    X['earliest_cr_line'] = X['earliest_cr_line'].dt.days\n",
    "    \n",
    "    # Create features for three employee titles: teacher, manager, owner\n",
    "    X['emp_title'] = X['emp_title'].str.lower()\n",
    "    X['emp_title_teacher'] = X['emp_title'].str.contains('teacher', na=False)\n",
    "    X['emp_title_manager'] = X['emp_title'].str.contains('manager', na=False)\n",
    "    X['emp_title_owner']   = X['emp_title'].str.contains('owner', na=False)\n",
    "    \n",
    "    # Drop categoricals with high cardinality\n",
    "    X = X.drop(columns=['emp_title', 'zip_code'])\n",
    "    \n",
    "    # Transform features with many nulls to binary flags\n",
    "    many_nulls = ['sec_app_mths_since_last_major_derog',\n",
    "                  'sec_app_revol_util',\n",
    "                  'sec_app_earliest_cr_line',\n",
    "                  'sec_app_mort_acc',\n",
    "                  'dti_joint',\n",
    "                  'sec_app_collections_12_mths_ex_med',\n",
    "                  'sec_app_chargeoff_within_12_mths',\n",
    "                  'sec_app_num_rev_accts',\n",
    "                  'sec_app_open_act_il',\n",
    "                  'sec_app_open_acc',\n",
    "                  'revol_bal_joint',\n",
    "                  'annual_inc_joint',\n",
    "                  'sec_app_inq_last_6mths',\n",
    "                  'mths_since_last_record',\n",
    "                  'mths_since_recent_bc_dlq',\n",
    "                  'mths_since_last_major_derog',\n",
    "                  'mths_since_recent_revol_delinq',\n",
    "                  'mths_since_last_delinq',\n",
    "                  'il_util',\n",
    "                  'emp_length',\n",
    "                  'mths_since_recent_inq',\n",
    "                  'mo_sin_old_il_acct',\n",
    "                  'mths_since_rcnt_il',\n",
    "                  'num_tl_120dpd_2m',\n",
    "                  'bc_util',\n",
    "                  'percent_bc_gt_75',\n",
    "                  'bc_open_to_buy',\n",
    "                  'mths_since_recent_bc']\n",
    "\n",
    "    for col in many_nulls:\n",
    "        X[col] = X[col].isnull()\n",
    "    \n",
    "    # For features with few nulls, do mean imputation\n",
    "    for col in X:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col] = X[col].fillna(X[col].mean())\n",
    "    \n",
    "    # Return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train = wrangle(X_train)\n",
    "X_val   = wrangle(X_val)\n",
    "X_test  = wrangle(X_test)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = X_train.isnull().sum()\n",
    "all(null_counts == 0)\n",
    "cardinality = X_train.select_dtypes(exclude='number').nunique()\n",
    "all(cardinality <= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.7209488082159045, total=   2.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7179909081557903, total=   2.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7068262082439076, total=   2.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7299839282729704, total=   2.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7199312704688474, total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.8s finished\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_transformed = encoder.fit_transform(X_train)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    class_weight='balanced', \n",
    "    min_samples_leaf=0.005, \n",
    "    n_jobs=-1)\n",
    "\n",
    "model.fit(X_train_transformed, y_train)\n",
    "permuter = PermutationImportance(model, scoring='roc_auc', n_iter=1, cv='prefit')\n",
    "permuter.fit(X_train_transformed, y_train)\n",
    "\n",
    "eli5.show_weights(permuter, top=None, feature_names=X_train_transformed.columns.tolist())\n",
    "\n",
    "subset = X_train.columns[permuter.feature_importances_ > 0]\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        class_weight='balanced', \n",
    "        min_samples_leaf=0.005, \n",
    "        n_jobs=-1)\n",
    ")\n",
    "\n",
    "cross_val_score(pipe, X_train[subset], y_train, cv=5, scoring='roc_auc', verbose=10)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "roc_auc_score(y_val, pipe.predict_proba(X_val)[:, 1])\n",
    "\n",
    "submission = sample_submission.copy() \n",
    "submission['charged_off'] = pipe.predict_proba(X_test)[:, 1] \n",
    "submission.to_csv('Model_RandomForrestClassifier_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
