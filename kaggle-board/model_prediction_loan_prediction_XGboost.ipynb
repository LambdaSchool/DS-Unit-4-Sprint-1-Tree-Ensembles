{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/d3/82a4b85a87ece114f6d0139d643580c726efa45fa4db3b81aed38c0156c5/category_encoders-1.3.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 18.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: pandas>=0.20.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (0.22.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (1.15.4)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (0.19.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.20.1->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.20.1->category_encoders) (2018.4)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-1.3.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/49/7e10686647f741bd9c8918b0decdb94135b542fe372ca1100739b8529503/xgboost-0.82-py2.py3-none-manylinux1_x86_64.whl (114.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 114.0MB 472kB/s eta 0:00:01    94% |██████████████████████████████▏ | 107.5MB 53.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.15.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "X_train = pd.read_csv('data/train_features.csv')\n",
    "X_test = pd.read_csv('data/test_features.csv')\n",
    "y_train = pd.read_csv('data/train_labels.csv')['charged_off']\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, train_size=40000, \n",
    "    random_state=42, stratify=y_train)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Drop some columns\n",
    "    X = X.drop(columns='id')  # id is random\n",
    "    X = X.drop(columns=['member_id', 'url', 'desc'])  # All null\n",
    "    X = X.drop(columns='title')  # Duplicative of purpose\n",
    "    X = X.drop(columns='grade')  # Duplicative of sub_grade\n",
    "    \n",
    "    # Transform sub_grade from \"A1\" - \"G5\" to 1.1 - 7.5\n",
    "    def wrangle_sub_grade(x):\n",
    "        first_digit = ord(x[0]) - 64\n",
    "        second_digit = int(x[1])\n",
    "        return first_digit + second_digit/10\n",
    "    \n",
    "    X['sub_grade'] = X['sub_grade'].apply(wrangle_sub_grade)\n",
    "\n",
    "    # Convert percentages from strings to floats\n",
    "    X['int_rate'] = X['int_rate'].str.strip('%').astype(float)\n",
    "    X['revol_util'] = X['revol_util'].str.strip('%').astype(float)\n",
    "        \n",
    "    # Transform earliest_cr_line to an integer: how many days it's been open\n",
    "    X['earliest_cr_line'] = pd.to_datetime(X['earliest_cr_line'], infer_datetime_format=True)\n",
    "    X['earliest_cr_line'] = pd.Timestamp.today() - X['earliest_cr_line']\n",
    "    X['earliest_cr_line'] = X['earliest_cr_line'].dt.days\n",
    "    \n",
    "    # Create features for three employee titles: teacher, manager, owner\n",
    "    X['emp_title'] = X['emp_title'].str.lower()\n",
    "    X['emp_title_teacher'] = X['emp_title'].str.contains('teacher', na=False)\n",
    "    X['emp_title_manager'] = X['emp_title'].str.contains('manager', na=False)\n",
    "    X['emp_title_owner']   = X['emp_title'].str.contains('owner', na=False)\n",
    "    \n",
    "    # Drop categoricals with high cardinality\n",
    "    X = X.drop(columns=['emp_title', 'zip_code'])\n",
    "    \n",
    "    # Transform features with many nulls to binary flags\n",
    "    many_nulls = ['sec_app_mths_since_last_major_derog',\n",
    "                  'sec_app_revol_util',\n",
    "                  'sec_app_earliest_cr_line',\n",
    "                  'sec_app_mort_acc',\n",
    "                  'dti_joint',\n",
    "                  'sec_app_collections_12_mths_ex_med',\n",
    "                  'sec_app_chargeoff_within_12_mths',\n",
    "                  'sec_app_num_rev_accts',\n",
    "                  'sec_app_open_act_il',\n",
    "                  'sec_app_open_acc',\n",
    "                  'revol_bal_joint',\n",
    "                  'annual_inc_joint',\n",
    "                  'sec_app_inq_last_6mths',\n",
    "                  'mths_since_last_record',\n",
    "                  'mths_since_recent_bc_dlq',\n",
    "                  'mths_since_last_major_derog',\n",
    "                  'mths_since_recent_revol_delinq',\n",
    "                  'mths_since_last_delinq',\n",
    "                  'il_util',\n",
    "                  'emp_length',\n",
    "                  'mths_since_recent_inq',\n",
    "                  'mo_sin_old_il_acct',\n",
    "                  'mths_since_rcnt_il',\n",
    "                  'num_tl_120dpd_2m',\n",
    "                  'bc_util',\n",
    "                  'percent_bc_gt_75',\n",
    "                  'bc_open_to_buy',\n",
    "                  'mths_since_recent_bc']\n",
    "\n",
    "    for col in many_nulls:\n",
    "        X[col] = X[col].isnull()\n",
    "    \n",
    "    # For features with few nulls, do mean imputation\n",
    "    for col in X:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col] = X[col].fillna(X[col].mean())\n",
    "    \n",
    "    # Return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train = wrangle(X_train)\n",
    "X_test  = wrangle(X_test)\n",
    "X_val  = wrangle(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(pipeline, X_train, y_train, X_test, name):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(roc_auc_score(y_val, pipe.predict_proba(X_val)[:, 1]))\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv') \n",
    "    submission = sample_submission.copy() \n",
    "    submission['charged_off'] = pipeline.predict_proba(X_test)[:, 1] \n",
    "    submission.to_csv( name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.7330665561586248, total= 4.4min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7276338386169755, total= 4.5min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7282776203628762, total= 4.4min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 13.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7306482479064141, total= 4.4min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 17.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.731095550701985, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 22.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 22.1min finished\n"
     ]
    }
   ],
   "source": [
    "################################ \n",
    "submission_url = '5_XgboostClassifier5a.csv'\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    XGBClassifier(\n",
    "        learning_rate = 0.1, \n",
    "        n_estimators=200,\n",
    "        eval_metric = \"auc\",\n",
    "        xgbclassifier__silent = False,\n",
    "        n_jobs=-1)\n",
    ")\n",
    "\n",
    "cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc', verbose=10)\n",
    "submission(pipe, X_train, y_train, X_test, submission_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.7321601325501664, total= 3.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7290753804139906, total= 3.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7297571157431308, total= 3.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 10.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.731738175292772, total= 3.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 14.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7320241895878264, total= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 17.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 17.8min finished\n"
     ]
    }
   ],
   "source": [
    "################################# \n",
    "# Add RobustScaler\n",
    "submission_url = '5_XgboostClassifier5b.csv'\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "pipe = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    RobustScaler(),\n",
    "    XGBClassifier(\n",
    "        learning_rate = 0.1, \n",
    "        n_estimators=200,\n",
    "        eval_metric = \"auc\",\n",
    "        xgbclassifier__silent = False,\n",
    "        n_jobs=-1)\n",
    "\n",
    ")\n",
    "\n",
    "cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc', verbose=10)\n",
    "submission(pipe, X_train, y_train, X_test, submission_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
